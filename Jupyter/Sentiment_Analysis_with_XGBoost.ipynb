{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4e8605f4-553e-426b-adf9-8714fd207855",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, cross_val_score,GridSearchCV, StratifiedKFold\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix,f1_score\n",
    "from sklearn.preprocessing import MinMaxScaler, LabelEncoder\n",
    "from xgboost import XGBClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.utils import resample\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b71844ea-04e5-4adc-9396-4f8d42950554",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "file_path = 'Balanced_Reviews(500).csv'\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Convert rating column to numeric\n",
    "data['rating'] = pd.to_numeric(data['rating'], errors='coerce')\n",
    "data = data.dropna(subset=['rating'])\n",
    "data['rating'] = data['rating'].astype(int)\n",
    "\n",
    "# Create sentiment column\n",
    "data['sentiment'] = data['rating'].apply(lambda x: 'positive' if x >= 4 else ('neutral' if x == 3 else 'negative'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cef6b84a-f11c-4a9e-8650-72ad2220bcbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop NaN values in content\n",
    "data = data.dropna(subset=['content'])\n",
    "\n",
    "# Separate majority and minority classes\n",
    "positive = data[data.sentiment == 'positive']\n",
    "neutral = data[data.sentiment == 'neutral']\n",
    "negative = data[data.sentiment == 'negative']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "023cad04-a75d-4bd1-9fa1-dd42dc6df253",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upsample minority classes\n",
    "neutral_upsampled = resample(neutral,\n",
    "                             replace=True,     # sample with replacement\n",
    "                             n_samples=len(positive),    # to match majority class\n",
    "                             random_state=42) # reproducible results\n",
    "negative_upsampled = resample(negative,\n",
    "                              replace=True,     # sample with replacement\n",
    "                              n_samples=len(positive),    # to match majority class\n",
    "                              random_state=42) # reproducible results\n",
    "\n",
    "# Combine majority class with upsampled minority classes\n",
    "upsampled = pd.concat([positive, neutral_upsampled, negative_upsampled])\n",
    "\n",
    "# Text data for training\n",
    "X = upsampled['content']\n",
    "y = upsampled['sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "31158686-72f9-4041-980c-99b95012ac61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.9973958333333334\n",
      "Testing Accuracy: 0.8916666666666667\n"
     ]
    }
   ],
   "source": [
    "# Split the data into training, validation, and test sets\n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_full, y_train_full, test_size=0.2, random_state=42)\n",
    "\n",
    "# Convert text data to TF-IDF features\n",
    "vectorizer = TfidfVectorizer(stop_words='english', max_features=5000)\n",
    "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
    "X_val_tfidf = vectorizer.transform(X_val)\n",
    "X_test_tfidf = vectorizer.transform(X_test)\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "y_train_encoded = label_encoder.fit_transform(y_train)\n",
    "y_test_encoded = label_encoder.transform(y_test)\n",
    "\n",
    "model_xgb = XGBClassifier()\n",
    "model_xgb.fit(X_train_tfidf, y_train_encoded)\n",
    "\n",
    "y_pred_train = model_xgb.predict(X_train_tfidf)\n",
    "y_pred_test = model_xgb.predict(X_test_tfidf)\n",
    "\n",
    "print(\"Training Accuracy:\", accuracy_score(y_train_encoded, y_pred_train))\n",
    "print(\"Testing Accuracy:\", accuracy_score(y_test_encoded, y_pred_test))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "44303ec8-13e5-4f9c-a325-1ec7ebef36f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.90      0.93        41\n",
      "           1       0.82      0.89      0.85        36\n",
      "           2       0.90      0.88      0.89        43\n",
      "\n",
      "    accuracy                           0.89       120\n",
      "   macro avg       0.89      0.89      0.89       120\n",
      "weighted avg       0.89      0.89      0.89       120\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print (classification_report(y_test_encoded,y_pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a4ad88fe-6fc7-4021-8915-e22c4884f788",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(model_xgb, open('Models/XGBoost.pkl', 'wb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (GPU)",
   "language": "python",
   "name": "gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
